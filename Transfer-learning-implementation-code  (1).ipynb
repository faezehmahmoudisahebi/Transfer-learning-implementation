{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet import ResNet50, ResNet101, ResNet152, preprocess_input\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# data_path = 'https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta data loading \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_to_metadata = 'D:/Data/HAM10000_metadata.csv'\n",
    "\n",
    "metadata =pd.read_csv(path_to_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.4618149,\n",
       " 1: 0.07665921,\n",
       " 2: 1.0,\n",
       " 3: 1.5718654,\n",
       " 4: 0.46769792,\n",
       " 5: 4.4695654,\n",
       " 6: 3.6197183}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_weights = {0:1, 1:1, 2:1, 3:10, 4:1, 5:20, 6:20}\n",
    "\n",
    "label = ['mel', 'nv', 'bcc',  'akiec', 'bkl', 'df', 'vasc']\n",
    "\n",
    "def estimate_class_weights(label, method = 'mfb'):\n",
    "    class_weights = np.zeros_like(label, dtype = np.float32)\n",
    "    counts = np.zeros_like(label)\n",
    "    for i,l in enumerate(label):\n",
    "        counts[i] = metadata[metadata['dx']==str(l)]['dx'].value_counts()[0]\n",
    "    counts = counts.astype(np.float32)\n",
    "    median_freq = np.median(counts)\n",
    "    mode_freq = np.max(counts)\n",
    "\n",
    "    func = lambda x:median_freq / x if method == 'mfb' else mode_freq/x\n",
    "    class_weights = list(map(func, counts))\n",
    "    weights = {i:class_weights[i] for i in range(7)}\n",
    "    \n",
    "    return weights\n",
    "\n",
    "\n",
    "class_weights = estimate_class_weights(label, method = 'mfb')\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self,\n",
    "                 batch_size = 5,\n",
    "                 dim = (224, 224),\n",
    "                 n_channels = 3,\n",
    "                 n_classes = 7,\n",
    "                 shuffle = True,\n",
    "                 images_address = \"D:\\\\Data\\\\New folder (3)\\\\HAM10000_images_part_1\",\n",
    "                 label_address = \"D:\\\\Data\\\\New folder (3)\\\\hmnist_8_8_L.csv\"\n",
    "                 ):\n",
    "\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.images_address = images_address\n",
    "        self.labels = pd.read_csv(label_address)\n",
    "        self.image_name = self.labels['image'].values\n",
    "        self.labels.drop(columns=['image'], inplace=True)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.image_name) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Find a list of labels\n",
    "        labels_index_temp = [self.image_name[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(labels_index_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.image_name))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "\n",
    "    def __data_generation(self, labels_index_temp):\n",
    "\n",
    "        # Generates data containing batch_size samples'\n",
    "\n",
    "        input_data = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        label = np.empty((self.batch_size, self.n_classes), dtype=np.float32)\n",
    "\n",
    "        for index, item in enumerate(labels_index_temp):\n",
    "\n",
    "            img = cv2.imread(self.images_address + item + '.jpg')\n",
    "            img = cv2.resize(img, self.dim, cv2.INTER_CUBIC)\n",
    "            input_data[index,] = tf.keras.applications.resnet50.preprocess_input(img)\n",
    "            label[index] = self.labels.values[np.where(self.image_name == item)]\n",
    "\n",
    "\n",
    "        return input_data.astype(np.float32), label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_tr = \"D:\\\\Data\\\\New folder (3)\\\\HAM10000_images_part_1\"\n",
    "label_path_tr = \"D:\\\\Data\\\\New folder (3)\\\\hmnist_8_8_L.csv\"\n",
    "\n",
    " \n",
    "batch_size = 5\n",
    "train_generator = DataGenerator(batch_size = batch_size, \n",
    "                               images_address = img_path_tr, \n",
    "                               label_address = label_path_tr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning - Feature represenation of ResNet50 with a customized learning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 702471    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,290,183\n",
      "Trainable params: 702,471\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_maps = ResNet50(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3)) \n",
    "model = keras.models.Sequential()\n",
    "feature_maps.trainable = False\n",
    "model.add(feature_maps)\n",
    "# model.add(keras.layers.MaxPool2D((7, 7)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(7, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('cancer_model_primary_frozen_layers_weighting.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another way of construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_model = feature_maps.output\n",
    "# target_model = keras.layers.AveragePooling2D(pool_size = (7, 7))(target_model)\n",
    "# target_model = keras.layers.Flatten()(target_model)\n",
    "# target_model = keras.layers.Dense(7, activation = 'softmax')(target_model)\n",
    "# model = keras.models.Model(inputs = feature_maps.input, outputs = target_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2003/2003 [==============================] - 731s 364ms/step - loss: 16.1588 - categorical_crossentropy: 40.0696 - accuracy: 0.4983 - val_loss: 27.8177 - val_categorical_crossentropy: 27.8177 - val_accuracy: 0.7158\n",
      "Epoch 2/10\n",
      "2003/2003 [==============================] - 661s 330ms/step - loss: 7.3646 - categorical_crossentropy: 24.2022 - accuracy: 0.6928 - val_loss: 57.1758 - val_categorical_crossentropy: 57.1758 - val_accuracy: 0.5316\n",
      "Epoch 3/10\n",
      "2003/2003 [==============================] - 676s 337ms/step - loss: 4.7099 - categorical_crossentropy: 18.4785 - accuracy: 0.7639 - val_loss: 54.4811 - val_categorical_crossentropy: 54.4811 - val_accuracy: 0.5316\n",
      "Epoch 4/10\n",
      "2003/2003 [==============================] - 657s 328ms/step - loss: 4.5688 - categorical_crossentropy: 19.6412 - accuracy: 0.7762 - val_loss: 35.6200 - val_categorical_crossentropy: 35.6200 - val_accuracy: 0.7158\n",
      "Epoch 5/10\n",
      "2003/2003 [==============================] - 630s 314ms/step - loss: 3.1183 - categorical_crossentropy: 13.7809 - accuracy: 0.8312 - val_loss: 28.9534 - val_categorical_crossentropy: 28.9534 - val_accuracy: 0.7000\n",
      "Epoch 6/10\n",
      "2003/2003 [==============================] - 585s 292ms/step - loss: 3.1197 - categorical_crossentropy: 11.9677 - accuracy: 0.8453 - val_loss: 39.2514 - val_categorical_crossentropy: 39.2514 - val_accuracy: 0.7316\n",
      "Epoch 7/10\n",
      "2003/2003 [==============================] - 592s 295ms/step - loss: 2.2604 - categorical_crossentropy: 10.1873 - accuracy: 0.8733 - val_loss: 59.6940 - val_categorical_crossentropy: 59.6940 - val_accuracy: 0.6737\n",
      "Epoch 8/10\n",
      "2003/2003 [==============================] - 602s 301ms/step - loss: 2.0621 - categorical_crossentropy: 8.8248 - accuracy: 0.8878 - val_loss: 53.8154 - val_categorical_crossentropy: 53.8154 - val_accuracy: 0.6579\n",
      "Epoch 9/10\n",
      "2003/2003 [==============================] - 614s 306ms/step - loss: 2.2935 - categorical_crossentropy: 10.3018 - accuracy: 0.8854 - val_loss: 58.3052 - val_categorical_crossentropy: 58.3052 - val_accuracy: 0.6421\n",
      "Epoch 10/10\n",
      "2003/2003 [==============================] - 612s 305ms/step - loss: 1.9682 - categorical_crossentropy: 8.7906 - accuracy: 0.9023 - val_loss: 46.1944 - val_categorical_crossentropy: 46.1944 - val_accuracy: 0.7316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab43491c88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_weights = {0:1, 1:1, 2:1, 3:10, 4:1, 5:20, 6:20}\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics =['categorical_crossentropy', 'accuracy'])\n",
    "\n",
    "model.fit(train_generator, \n",
    "          validation_data = validation_generator, \n",
    "          epochs = 10,  \n",
    "          shuffle = True, \n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = DataGenerator(batch_size = 1, \n",
    "                               images_address = img_path_val, \n",
    "                               label_address = label_path_val)\n",
    "\n",
    "\n",
    "y_tr_pre = []\n",
    "y_tr_te = []\n",
    "for x, y in validation_generator:\n",
    "    y_pre_te = model.predict(x)\n",
    "    y_tr_pre.append(np.argmax(y_pre_te[0], axis = 0))\n",
    "    y_tr_te.append(np.argmax(y[0], axis = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15   2   0   1   3   0   0]\n",
      " [  7 106   2   0   8   0   0]\n",
      " [  0   0   8   2   4   1   0]\n",
      " [  1   0   1   1   5   0   0]\n",
      " [  6   2   1   1  12   0   0]\n",
      " [  0   0   0   0   0   1   0]\n",
      " [  1   0   0   0   1   0   1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_tr_te, y_tr_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.71      0.59        21\n",
      "           1       0.96      0.86      0.91       123\n",
      "           2       0.67      0.53      0.59        15\n",
      "           3       0.20      0.12      0.15         8\n",
      "           4       0.36      0.55      0.44        22\n",
      "           5       0.50      1.00      0.67         1\n",
      "           6       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.75       193\n",
      "   macro avg       0.60      0.59      0.55       193\n",
      "weighted avg       0.79      0.75      0.76       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_tr_te, y_tr_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(batch_size = 1, \n",
    "                               images_address = img_path_tr, \n",
    "                               label_address = label_path_tr)\n",
    "\n",
    "y_tr_pre = []\n",
    "y_tr_te = []\n",
    "for x, y in train_generator:\n",
    "    y_pre_te = model.predict(x)\n",
    "    y_tr_pre.append(np.argmax(y_pre_te[0], axis = 0))\n",
    "    y_tr_te.append(np.argmax(y[0], axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1053   46    4    4    6    0    0]\n",
      " [ 409 5963   59   33  218   18    5]\n",
      " [   5    8  481    4   15    1    0]\n",
      " [  10    1    1  308    7    0    0]\n",
      " [  70   42    2    8  976    0    1]\n",
      " [   1    0    1    1    1  111    0]\n",
      " [   1    7    2    1    2    1  128]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_tr_te, y_tr_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.95      0.79      1113\n",
      "           1       0.98      0.89      0.93      6705\n",
      "           2       0.87      0.94      0.90       514\n",
      "           3       0.86      0.94      0.90       327\n",
      "           4       0.80      0.89      0.84      1099\n",
      "           5       0.85      0.97      0.90       115\n",
      "           6       0.96      0.90      0.93       142\n",
      "\n",
      "    accuracy                           0.90     10015\n",
      "   macro avg       0.86      0.92      0.89     10015\n",
      "weighted avg       0.92      0.90      0.90     10015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_tr_te, y_tr_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
